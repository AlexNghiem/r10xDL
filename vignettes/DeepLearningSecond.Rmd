---
title: "DeepLearningSecond"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(BiocManager)
library(SingleCellExperiment)
library(purrr)
library(DropletUtils)
library(keras)
library(scran)
library(scater)
library(r10xDL)
library(umap)
```

Here we will be doing a quick foray into deep learning using the 10X genomics data published in June 2019. This data tracks around 150,000 cells across 4 different donors. For each cell, the data specify gene expression data, protein expression data, and antigen specificity data.

Broadly, our goal is to create a machine learning approach to predict protein expression from gene expression data. We have a lot of data here to work with, but it is not clear which machine learning approach will best be able to do this job. First, we will look to do some processing and analysis of the data set.

For now, we will just proceed with a basic neural net.

Please note that several hyperparameters have been lowered to help the vignette run quickly. I will mark these spots with more optimal values.

## Cut up the data
```{r reading}
library(DropletUtils)
library(BiocManager)
library(SingleCellExperiment)
##55206 cells
SCE <- read10xCounts("10Xdata/vdj_v1_hs_aggregated_donor1_filtered_feature_bc_matrix.h5")

trainingSize = 10000 #how many cells to train on (this affects speed linearly.. 50000 is optimal)
testingSize = 5000 #how many cells to test on (this does not affect speed much.. 5000 is plenty)

geneTrainingSCE <- SCE[,1:trainingSize] #takes the first however many cells as training data
geneTestingSCE <- SCE[,(trainingSize+1):(trainingSize+testingSize)] #takes the next however many cells as testing data

proteinGREP <- "CD.*|Ig.*|HLA-DR"
proteinList <- grep(proteinGREP, rowData(geneTrainingSCE)$ID)
getProteinMatrix <- function(x) { #from an SCE, gets the transposed matrix of proteins
  x[proteinList] %>%
    counts() %>%
    as.matrix() %>%
    t() %>%
    clr()
}

# TENSORFLOW WILL BREAK if fed any dashes!! we will replace dashes in the protein names with underscores
fixProteinColNames <- function(x) {
  colnames(x)[colnames(x) == "CD279_PD-1"] <- "CD279_PD_1"
  colnames(x)[colnames(x) == "HLA-DR"] <- "HLA_DR"
  x
}

#get normalized protein data matrices
library(purrr)
library(compositions)
proteinTrainingData <- geneTrainingSCE %>%
  getProteinMatrix() %>%
  fixProteinColNames()
proteinTestingData <- geneTestingSCE %>%
  getProteinMatrix() %>%
  fixProteinColNames()



geneTrainingSCE <- geneTrainingSCE[rowData(geneTrainingSCE)$Type == "Gene Expression"]
geneTestingSCE <- geneTestingSCE[rowData(geneTestingSCE)$Type == "Gene Expression"]

```

## Cleaning the data
Now we will clean and prepare the data to be used in the model. We use some basic techniques like filtering out poorly-expressed genes and normalizing the GEX matrix. 

```{r clean}
# I will clean them and prepare them to be used in the model

#fix count matrices
counts(geneTrainingSCE) <- as.matrix(counts(geneTrainingSCE))
counts(geneTestingSCE) <- as.matrix(counts(geneTestingSCE))

#remove low frequency genes from the SCE (keep those with 1 read in at least 5% of cells)
min_reads <- 1
min_cells <- 0.05 * ncol(geneTrainingSCE) 
#calculate a boolean vector for which genes to keep
keep <- rowSums(counts(geneTrainingSCE) >= min_reads) >= min_cells
#subset both SCEs using this vector
geneTrainingSCE <- geneTrainingSCE[keep, ]
geneTestingSCE <- geneTestingSCE[keep, ]

#for readability, swap rownames from row ID to row symbol
library(scater)
featureNames <- uniquifyFeatureNames(ID = rowData(geneTrainingSCE)$ID, names = rowData(geneTrainingSCE)$Symbol)
rownames(geneTrainingSCE) <- featureNames
rownames(geneTestingSCE) <- featureNames

#normalize
geneTrainingSCE <- scater::normalize(geneTrainingSCE)
geneTestingSCE <- scater::normalize(geneTestingSCE)
```

## Select Data
I started by predicting a single protein's expression from the GEX data, which went fine, so I bumped things up and am now predicting and training on all of the protein labels.

I also have decided to train the model on the more highly variable genes. Hopefully this reduces noise in the model and makes it easier and faster for the model to train.

```{r selectData}
#find highly variable genes
library(scran)
fit <- trendVar(geneTrainingSCE, use.spikes = FALSE)
dec <- decomposeVar(geneTrainingSCE, fit)
hvg <- dec$bio > 0 # save vector of genes

getGeneMatrix <- function(x) {
  #subset both SCE's with that set of genes
  x[hvg,] %>%
  logcounts() %>%
  t()
}

trainingData <- getGeneMatrix(geneTrainingSCE)
testingData <- getGeneMatrix(geneTestingSCE)

#choose output protein(s)
#CD127 has almost no expression
select <- c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE)
  #rep(TRUE, 14)
  # 1: CD3, 2: CD19, 3: CD45RA, 4: CD4, 5: CD8a, 6: CD14, 7: CD45RO, 8: CD279_PD_1, 9: IgG1, 10: IgG2a, 11: IgG2b, 12: CD127, 13: CD197_CR7, 14: HLA_DR

trainingLabels <- proteinTrainingData[,select]
testingLabels <- proteinTestingData[,select]

```

## Building the model

I have tried many types of model, various learning rates, layer sizes, number of layers, combinations of activation functions, dropout layers, batch sizes, etc. I have found that these current parameters do pretty well overall. Here is a compilation of what I know about these things, and what they do:
* Learning rate - The rate at which the model changes its parameters. On the order of 0.0005. Values between 0.0002 and 0.001 seem to work fine.
  + If this is too high, the model will jump between local minima and potentially never converge. In the loss graph, this correlates to great variance between adjacent epochs. If the model has not converged by the end of the run, it is probably losing a lot of prediction accuracy.
  + If this is too low, the model will simply take a long time to converge. Not really an issue.
* Layer sizes - This is one I don't know too well. I think it is a bad thing for the model to have too few layers in a bottleneck (less than 5?). Even though a 2D representation may preserve some information in a tSNE/UMAP plot, for example, I believe that neural nets have a hard time procedurally creating that reversible transformation. Other than that, I've been playing with the settings and haven't seen many patterns. 
* Number of layers - Again, I haven't seen much difference. I also haven't spent too much time looking. Usually ~3 is a solid number.
* Activation function - RELU is an activation function which zeros out any activation below 0, and sigmoid squishes any value asymptotically between 0 and 1. Basically the difference is that RELU destroys negative values, and sigmoid doesn't. I dabbled briefly with sigmoid activation and it ruined everything. I have been sticking to RELU. I think it does a good job of zeroing out noise in a lot of cases. I wouldn't be opposed to having a sigmoid layer here or there, but I do think the model requires 1 relu layer at a minimum. 
* Dropout - Dropout is the process of choosing randomly some proportion of nodes from a layer to get dropped completely. This helps ensure that the model is training using all available data, as sometimes key genes are not included. Using dropout does seem to have a large positive effect on performance. Good values seem to range from ~.2 to ~.5. 
* Batch size - This is the number of samples that the model goes through before it decides which direction to train. Generally a power of 2, often 32, 64, or 128. Small sizes will mean the model is often pulled different directions towards different local minima, whereas large sizes will cause the model to move in the same direction. I find that 128 works nicely, but haven't played with it too much.

The IgG proteins are 3 proteins which are not of interest to us, and are just contributing noise. I will lower the weights on those so they don't interfere with the model's performance.

Evolution of model:
1. I started with only a couple of layers, with high dimensionality (around 64), predicting only a single protein expression. This was taking a long time to train the network with this large parameter space to train.
2. The training speed went down a lot as I brought down the dimension of the layers, closer to 8 or 4. This didn't seem to affect the performance, so I kept it to keep training times down.
3. I added a dropout layer, and this vastly improved performance.
4. I added the extra proteins, which actually decreased the performance of the couple proteins I was originally looking at

```{r buildModel}
# Build the keras model

library(keras)

inputs <- layer_input(shape = c(dim(trainingData)[2]))
output0 <- inputs %>%
  layer_dropout(rate = .25) %>%
  layer_dense(units = 64, activation = 'relu') %>%
  layer_dense(units = 8, activation = 'relu')

# all of the layers are shared up until the last two, during which each protein gets its own set of 64 nodes leading to one output
makeOutputLayer <- function(x) {
  layer_dense(output0, units=4) %>%
    layer_dense(units=1, name= colnames(trainingLabels)[x])
}

outputs <- lapply(1:dim(trainingLabels)[2], makeOutputLayer)

model <- keras_model(inputs=inputs, outputs=outputs)

model %>% compile(
  loss = "mse",
  optimizer = optimizer_rmsprop(lr = .0005),
  metrics = list("mean_absolute_error"),
  loss_weights = c(1,1,1,1,1,1,1,1,.5,.5,.5,1,1)
)

model %>% summary()

# Display training progress by printing a single dot for each completed epoch.
print_dot_callback <- callback_lambda(
  on_epoch_end = function(epoch, logs) {
    if (epoch %% 50 == 0) cat("\n")
    cat(".")
  }
)    
#epochs refers to how many passes through the data we make, and affects run time linearly. we can use early stopping techniques to set this, or we can just give it a set value to reach. 50 to 100 is usually good, but here I use 25 to help it train fast.
epochs <- 25
batch_size <- 128

```

```{r trainModel, results = 'hide'}
# Train the model
history <- model %>% fit(
  x = trainingData,
  y = lapply(1:dim(trainingLabels)[2], function(x) {trainingLabels[,x]}),
  batch_size = batch_size,
  epochs = epochs,
  validation_split = 0.2,
  verbose = 0,
  callbacks = list(print_dot_callback)
)
```

Various tests to do. 

```{r graph, echo = FALSE}
# Tests the model against the testing data.


scatter <- function(x, y=".") {
  
  
  plot(testingLabels[,x], unlist(predict(model, testingData)[x]), xlab = paste(colnames(testingLabels)[x],"log value from data"), ylab = "Log value predicted by model", pch = y)
  
}

scatters <- function() {
  par(mfrow = c(3,5))
  lapply(1:13, scatter)
}

lossPlots <- function() {
  par(mfrow = c(3,5))
  plot(history$metrics$val_CD3_mean_absolute_error, xlab="epoch", ylab="CD3 mae")
  plot(history$metrics$val_CD19_mean_absolute_error, xlab="epoch", ylab="CD19 mae")
  plot(history$metrics$val_CD45RA_mean_absolute_error, xlab="epoch", ylab="CD45RA mae")
  plot(history$metrics$val_CD4_mean_absolute_error, xlab="epoch", ylab="CD4 mae")
  plot(history$metrics$val_CD8a_mean_absolute_error, xlab="epoch", ylab="CD8a mae") #5
  plot(history$metrics$val_CD14_mean_absolute_error, xlab="epoch", ylab="CD14 mae") 
  plot(history$metrics$val_CD45RO_mean_absolute_error, xlab="epoch", ylab="CD45RO mae")
  plot(history$metrics$val_CD279_PD_1_mean_absolute_error, xlab="epoch", ylab="CD279_PD_1 mae")
  plot(history$metrics$val_IgG1_mean_absolute_error, xlab="epoch", ylab="IgG1 mae")
  plot(history$metrics$val_IgG2a_mean_absolute_error, xlab="epoch", ylab="IgG2a mae") #10
  plot(history$metrics$val_IgG2b_mean_absolute_error, xlab="epoch", ylab="IgG2b mae")
  #this one has almost no expression
  #plot(history$metrics$val_CD127_mean_absolute_error, xlab="epoch", ylab="CD127 mae")
  plot(history$metrics$val_CD197_CCR7_mean_absolute_error, xlab="epoch", ylab="CD197_CCR7 mae")
  plot(history$metrics$val_HLA_DR_mean_absolute_error, xlab="epoch", ylab="HLA_DR mae")
}

correlations <- function(){
  predictions <- predict(model, testingData)
  total <- 0
  for (i in 1:dim(trainingLabels)[2]) {
    corr <- cor(as.numeric(unlist(predictions[i])), testingLabels[,i])
    if (!is.na(corr)){
      print(paste("The correlation between predicted and actual values for", colnames(testingLabels)[i], "is", corr))
      if (corr > 0) {
        total <- total + corr^2
      }
      else {
        total <- total - corr^2
      }
    }
  }
  print(paste("The sum of squared correlations is", total))
}

CD <- function() {
  plot(history, metrics = paste(c("CD45RA", "CD45RO"), "_mean_absolute_error", sep = ""), smooth = FALSE)
}

```

```{r print}
lossPlots()
scatters()
correlations()
```

# Discussion

Overall the results are relatively good. Considering that we are predicting within a single cell type, a good fraction of the variance in the protein expression can be explained by the gene quantities. If the model contained multiple types of cells, a lot more of the variance probably could be explained, as it is easier to predict expression using cell type markers than using other genes. 





